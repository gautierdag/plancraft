{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.5% that image 0 is 'a photo of 2 cats'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import torch\n",
    "\n",
    "model = AutoModel.from_pretrained(\"google/siglip-so400m-patch14-384\")\n",
    "processor = AutoProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "texts = [\"a photo of 2 cats\", \"a photo of 2 dogs\"]\n",
    "inputs = processor(text=texts, images=image, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits_per_image = outputs.logits_per_image\n",
    "probs = torch.sigmoid(logits_per_image) # these are the probabilities\n",
    "print(f\"{probs[0][0]:.1%} that image 0 is '{texts[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n",
      "Chat templates should be in a 'chat_template.json' file but found key='chat_template' in the processor's config. Make sure to move your template to its own file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dialogue dataset\n",
      "Loading images\n",
      "Loading dialogue dataset\n",
      "Loading images\n"
     ]
    }
   ],
   "source": [
    "# processor.tokenizer.encode()\n",
    "from plancraft.train.dataset import get_dataset_and_collate\n",
    "dataset, val_dataset, collate_fn = get_dataset_and_collate(\"idefics2\", 16000, 1000, \"oa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'role': 'system',\n",
       "   'content': [{'text': 'You are crafting in Minecraft. You need to decide on the next action.\\n\\nYou must output an action like the following:\\nact: move from slot X to slot Y with quantity Z\\n\\nThere are two types of actions\\n- move\\n- smelt\\n\\nThe first 10 slots in the inventory are reserved for crafting and correspond to the minecraft crafting table. \\n\\n[1, 2, 3] \\n[4, 5, 6] -> [0]\\n[7, 8, 9]\\n\\nThe crafting matrix is a 3x3 grid, and the output is sent to slot 0.\\nYou cannot move or smelt items into output slot 0.\\nThe remaining slots (10-45) are for storing items.\\n',\n",
       "     'type': 'text'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'image'},\n",
       "    {'text': 'Craft an item of type: mojang_banner_pattern', 'type': 'text'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'text': 'act: move from slot 22 to slot 1 with quantity 1',\n",
       "     'type': 'text'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'image'},\n",
       "    {'text': 'Craft an item of type: mojang_banner_pattern', 'type': 'text'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'text': 'act: move from slot 38 to slot 2 with quantity 1',\n",
       "     'type': 'text'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'image'},\n",
       "    {'text': 'Craft an item of type: mojang_banner_pattern', 'type': 'text'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'text': 'act: move from slot 0 to slot 11 with quantity 1',\n",
       "     'type': 'text'}]}],\n",
       " [<PIL.Image.Image image mode=RGB size=171x164>,\n",
       "  <PIL.Image.Image image mode=RGB size=171x164>,\n",
       "  <PIL.Image.Image image mode=RGB size=171x164>])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory = [\n",
    "#     {\"slot\": 13, \"type\": \"stick\", \"quantity\": 2},\n",
    "#     {\"slot\": 20, \"type\": \"acacia_log\", \"quantity\": 1},\n",
    "#     {\"slot\": 43, \"type\": \"dead_fire_coral\", \"quantity\": 55},\n",
    "#     {\"slot\": 27, \"type\": \"acacia_leaves\", \"quantity\": 11},\n",
    "#     {\"slot\": 28, \"type\": \"brown_mushroom\", \"quantity\": 23},\n",
    "#     {\"slot\": 14, \"type\": \"llama_spawn_egg\", \"quantity\": 22},\n",
    "#     {\"slot\": 45, \"type\": \"bat_spawn_egg\", \"quantity\": 6},\n",
    "#     {\"slot\": 23, \"type\": \"oak_leaves\", \"quantity\": 8},\n",
    "#     {\"slot\": 34, \"type\": \"diorite_slab\", \"quantity\": 38},\n",
    "#     {\"slot\": 22, \"type\": \"dark_prismarine_slab\", \"quantity\": 54},\n",
    "# ]\n",
    "\n",
    "class TypeEmbedding(nn.Module):\n",
    "    def __init__(self, model=AutoModel, tokenizer=AutoTokenizer):\n",
    "        super(TypeEmbedding, self).__init__()\n",
    "        self.embedding_dim = model.config.hidden_size\n",
    "        self.learnable_params = nn.Parameter(torch.randn(self.embedding_dim))\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cache = {}\n",
    "\n",
    "    def forward(self, object_types: list[str]):\n",
    "        batch, new_types = ([], [])\n",
    "        for object_type in object_types:\n",
    "            if object_type not in self.cache:\n",
    "                batch.append(object_type)\n",
    "                new_types.append(object_type)\n",
    "        if len(new_types) > 0:\n",
    "            inputs = self.tokenizer(new_types, return_tensors=\"pt\", padding=True)\n",
    "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            for i, object_type in enumerate(new_types):\n",
    "                type_embedding = outputs.last_hidden_state[i].mean(dim=0)\n",
    "                self.cache[object_type] = type_embedding\n",
    "        embeddings = [\n",
    "            self.cache[object_type] + self.learnable_params\n",
    "            for object_type in object_types\n",
    "        ]\n",
    "        return torch.stack(embeddings)\n",
    "\n",
    "class InventoryEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=AutoModel,\n",
    "        tokenizer=AutoTokenizer,\n",
    "        max_quantity=64,\n",
    "        max_slot=46,\n",
    "    ):\n",
    "        super(InventoryEncoder, self).__init__()\n",
    "        hidden_size = model.config.hidden_size\n",
    "        self.type_embedding = TypeEmbedding(model, tokenizer)\n",
    "        self.quantity_embedding = nn.Embedding(max_quantity, hidden_size)\n",
    "        self.slot_embedding = nn.Embedding(max_slot, hidden_size)\n",
    "        self.combine = nn.Linear(\n",
    "            hidden_size * 3,\n",
    "            hidden_size,\n",
    "        )\n",
    "\n",
    "    def forward(self, inventory: list[dict]):\n",
    "        type_embeddings = self.type_embedding([item[\"type\"] for item in inventory])\n",
    "        quantities = torch.tensor(\n",
    "            [item[\"quantity\"] for item in inventory], dtype=torch.long\n",
    "        )\n",
    "        slots = torch.tensor([item[\"slot\"] for item in inventory], dtype=torch.long)\n",
    "\n",
    "        quantities = quantities.cuda()\n",
    "        slots = slots.cuda()\n",
    "\n",
    "        quantity_embeddings = self.quantity_embedding(quantities)\n",
    "        slot_embeddings = self.slot_embedding(slots)\n",
    "        x_concat = torch.cat(\n",
    "            [type_embeddings, quantity_embeddings, slot_embeddings], dim=-1\n",
    "        )\n",
    "        embed = self.combine(x_concat).mean(dim=0)\n",
    "        return embed\n",
    "\n",
    "\n",
    "encoder = InventoryEncoder(model, tokenizer)\n",
    "encoder = encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InventoryGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=AutoModel,\n",
    "        tokenizer=AutoTokenizer,\n",
    "        max_quantity=64,\n",
    "        max_slot=46,\n",
    "    ):\n",
    "        super(InventoryGenerator, self).__init__()\n",
    "        hidden_size = model.config.hidden_size\n",
    "        self.max_quantity = max_quantity\n",
    "        self.max_slot = max_slot\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size * 3)\n",
    "        self.type_decoder = TypeEmbedding(model, tokenizer)\n",
    "        self.quantity_decoder = nn.Linear(hidden_size, max_quantity)\n",
    "        self.slot_decoder = nn.Linear(hidden_size, max_slot)\n",
    "\n",
    "    def forward(self, inventory_embedding):\n",
    "        x = self.fc(inventory_embedding)\n",
    "\n",
    "        type_embeds, quantity_embeds, slot_embeds = torch.split(\n",
    "            x, self.hidden_size, dim=-1\n",
    "        )\n",
    "\n",
    "        # Decode type embeddings\n",
    "        decoded_types = self.type_decoder.decode(type_embeds)\n",
    "\n",
    "        # Decode quantity and slot embeddings\n",
    "        quantities = self.quantity_decoder(quantity_embeds)\n",
    "        slots = self.slot_decoder(slot_embeds)\n",
    "\n",
    "        # Convert logits to indices\n",
    "        quantities = torch.argmax(quantities, dim=-1)\n",
    "        slots = torch.argmax(slots, dim=-1)\n",
    "\n",
    "        # Create the decoded inventory list\n",
    "        decoded_inventory = []\n",
    "        for obj_type, quantity, slot in zip(decoded_types, quantities, slots):\n",
    "            decoded_inventory.append(\n",
    "                {\n",
    "                    \"type\": obj_type,\n",
    "                    \"quantity\": quantity.item(),\n",
    "                    \"slot\": slot.item(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return decoded_inventory\n",
    "\n",
    "\n",
    "# Example of how to use the InventoryEmbedding and InventoryGenerator\n",
    "class InventoryAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=AutoModel,\n",
    "        tokenizer=AutoTokenizer,\n",
    "        max_quantity=64,\n",
    "        max_slot=46,\n",
    "    ):\n",
    "        super(InventoryAutoencoder, self).__init__()\n",
    "        self.encoder = InventoryEncoder(model, tokenizer, max_quantity, max_slot)\n",
    "        self.decoder = InventoryGenerator(model, tokenizer, max_quantity, max_slot)\n",
    "\n",
    "    def forward(self, inventory: list[dict]):\n",
    "        encoded = self.encoder(inventory)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "# Example usage\n",
    "inventory = [\n",
    "    {\"slot\": 13, \"type\": \"stick\", \"quantity\": 2},\n",
    "    {\"slot\": 20, \"type\": \"acacia_log\", \"quantity\": 1},\n",
    "    {\"slot\": 43, \"type\": \"dead_fire_coral\", \"quantity\": 55},\n",
    "    {\"slot\": 27, \"type\": \"acacia_leaves\", \"quantity\": 11},\n",
    "    {\"slot\": 28, \"type\": \"brown_mushroom\", \"quantity\": 23},\n",
    "    {\"slot\": 14, \"type\": \"llama_spawn_egg\", \"quantity\": 22},\n",
    "    {\"slot\": 45, \"type\": \"bat_spawn_egg\", \"quantity\": 6},\n",
    "    {\"slot\": 23, \"type\": \"oak_leaves\", \"quantity\": 8},\n",
    "    {\"slot\": 34, \"type\": \"diorite_slab\", \"quantity\": 38},\n",
    "    {\"slot\": 22, \"type\": \"dark_prismarine_slab\", \"quantity\": 54},\n",
    "]\n",
    "\n",
    "autoencoder = InventoryAutoencoder(model, tokenizer)\n",
    "autoencoder = autoencoder.to(\"cuda\")\n",
    "encoded_inventory = autoencoder.encoder(inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.decoder(encoded_inventory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/train.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5024,  0.7074,  1.2459,  ...,  0.2150, -0.3527, -0.0361],\n",
       "       device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(data[0][\"slotted_inventory\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data/train.json\n",
    "\n",
    "# with open('data/train.json') as f:\n",
    "#     data = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
